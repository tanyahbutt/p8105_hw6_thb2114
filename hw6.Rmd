---
title: "P8105 Homework 6 - Tanya Butt (thb2114)"
output: github_document
---

```{r, echo = FALSE, message = FALSE}
library(tidyverse)
library(patchwork)
knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Problem 1

```{r, collapse = TRUE}
birthweight_df = 
  read_csv("birthweight.csv") %>% 
  janitor::clean_names() %>% 
  mutate(
    babysex = as.factor(babysex),
    malform = as.factor(malform),
    frace = as.factor(frace),
    mrace = as.factor(mrace)
  ) %>% 
  select(-c(pnumlbw, pnumsga)) 
```

```{r, collapse = TRUE}
fit_df = 
  birthweight_df %>% 
  select(gaweeks, momage, delwt, wtgain, bwt)

fit = lm(bwt ~ gaweeks + momage + delwt  + wtgain, data = fit_df) 

fit_df %>% 
  modelr::add_residuals(fit) %>% 
  modelr::add_predictions(fit) %>% 
  ggplot(aes(x = pred, y = resid)) + geom_point()

fit


```

```{r}
fit_alt_1 = lm(bwt ~ blength + gaweeks, data = birthweight_df) %>% 
  broom::tidy()

fit_alt_1

fit_alt_2 = lm(bwt ~ bhead + blength + babysex + bhead*blength + bhead*babysex +
            blength*babysex + bhead*blength*babysex, data = birthweight_df) %>% 
  broom::tidy()

fit_alt_2
```

## Problem 2

Loading the 2017 Central Park weather data:
```{r, collapse = TRUE}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())

set.seed(1)
```

Creating 5000 bootstrap samples:
```{r, collapse = TRUE}
boot_sample = function(df) {
  sample_frac(df, replace = TRUE)
}

boot_straps = 
  tibble(
    strap_number = 1:5000,
    strap_sample = rerun(5000, boot_sample(weather_df))
  )

boot_straps
```

Determining the distribution of r-squared hat:
```{r, collapse = TRUE}
bootstrap_results_1 = 
  boot_straps %>% 
  mutate(
    models = map(strap_sample, ~lm(tmax ~ tmin, data = .x) ),
    results = map(models, broom::glance)) %>% 
  select(-strap_sample, -models) %>% 
  unnest(results)
  
bootstrap_results_1_graph = ggplot(bootstrap_results_1, aes(x = r.squared)) + 
  geom_density()

bootstrap_results_1_graph
```

The distribution has a bit of a heavy tail extending to the lower values, 
suggesting there may be outliers included in the bootstrap sample.

Below is a table of the 95% CI for r hat squared calculated using the 5000 
bootstrap samples:
```{r, collapse = TRUE}
bootstrap_results_1 %>% 
  summarize(
    ci_lower = quantile(r.squared, 0.025),
    ci_upper = quantile(r.squared, 0.975)) %>% 
  knitr::kable()
```

Determining the distribution of log(beta zero hat * beta one hat):
```{r, collapse = TRUE}
bootstrap_results_2 = 
  boot_straps %>% 
  mutate(
    models = map(strap_sample, ~lm(tmax ~ tmin, data = .x) ),
    results = map(models, broom::tidy)) %>% 
  select(-strap_sample, -models) %>% 
  unnest(results) %>%
  select(strap_number, term, estimate) %>% 
  pivot_wider(
    names_from = term,
    values_from = estimate
  ) %>% 
  rename(beta_zero = `(Intercept)`) %>% 
  rename(beta_one = tmin) %>% 
  mutate(log_interaction = log(beta_zero*beta_one))

bootstrap_results_2_graph = ggplot(bootstrap_results_2, aes(x = log_interaction)) + 
  geom_density()
  
bootstrap_results_2_graph
```

The distribution appears closer to normal than the r-squared hat distribution. 
There is a bit of a "shoulder" in the upper values, which may be related to the
frequency of outliers in the bootstrap sample.

Below is a table of the 95% CI for the log(beta zero hat * beta one hat) 
calculated using the 5000 bootstrap samples:
```{r, collapse = TRUE}
bootstrap_results_2 %>% 
  summarize(
    ci_lower = quantile(log_interaction, 0.025),
    ci_upper = quantile(log_interaction, 0.975)) %>% 
  knitr::kable()
```


